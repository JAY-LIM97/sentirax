"""
TOP 10 ì¢…ëª© ëª¨ë¸ í•™ìŠµ ë° ë°±í…ŒìŠ¤íŒ…

ğŸ¯ ëª©ì :
- ë‚˜ìŠ¤ë‹¥ ê±°ë˜ëŸ‰ TOP 10 ì¢…ëª© ì „ì²´ í•™ìŠµ
- ê° ì¢…ëª©ë³„ ëª¨ë¸ ì €ì¥
- í†µí•© ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±

ğŸ“Š ëŒ€ìƒ:
NVDA, INTC, TSLA, AMZN, AAPL, NFLX, MSFT, AMD, MU, GOOGL
"""

import sys
import os
import io

# Windows í•œê¸€/ì´ëª¨ì§€ ì¶œë ¥ ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
import pickle
from datetime import datetime
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, f1_score

from core.feature_engineer import FeatureEngineer

# TOP 10 ì¢…ëª©
TOP10_TICKERS = ['NVDA', 'INTC', 'TSLA', 'AMZN', 'AAPL', 'NFLX', 'MSFT', 'AMD', 'MU', 'GOOGL']


def train_and_backtest(ticker: str, save_model: bool = True):
    """
    ë‹¨ì¼ ì¢…ëª© í•™ìŠµ ë° ë°±í…ŒìŠ¤íŒ…

    Args:
        ticker: ì¢…ëª© í‹°ì»¤
        save_model: ëª¨ë¸ ì €ì¥ ì—¬ë¶€

    Returns:
        ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """

    print(f"\n{'='*70}")
    print(f"ğŸ¯ {ticker} ëª¨ë¸ í•™ìŠµ ë° ë°±í…ŒìŠ¤íŒ…")
    print(f"{'='*70}")

    try:
        # 1. ë°ì´í„° ë¡œë“œ
        print(f"\n1ï¸âƒ£ ë°ì´í„° ë¡œë“œ...")
        data_dir = os.path.join(os.path.dirname(__file__), '..', 'data')
        data_file = os.path.join(data_dir, f'{ticker.lower()}_top10_200days.csv')

        if not os.path.exists(data_file):
            print(f"âŒ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {data_file}")
            return None

        df = pd.read_csv(data_file, index_col=0)
        df.index = pd.to_datetime(df.index, utc=True).tz_localize(None)
        print(f"  âœ… {len(df)}ê°œ í–‰ ë¡œë“œ")

        # 2. Feature Engineering
        print(f"\n2ï¸âƒ£ Feature Engineering...")
        engineer = FeatureEngineer(label_threshold=1.0)

        # prepare_ml_data ì‚¬ìš© (ìë™ìœ¼ë¡œ featuresì™€ labels ìƒì„±)
        X_clean, y_clean = engineer.prepare_ml_data(df)

        # í•´ë‹¹ ì¸ë±ìŠ¤ë¡œ dfë„ í•„í„°ë§
        df_clean = df.loc[X_clean.index]

        feature_cols = X_clean.columns.tolist()

        # 3. Train/Test Split (80/20)
        print(f"\n3ï¸âƒ£ Train/Test Split (80/20)...")
        split_idx = int(len(X_clean) * 0.8)

        X_train = X_clean.iloc[:split_idx]
        y_train = y_clean.iloc[:split_idx]
        X_test = X_clean.iloc[split_idx:]
        y_test = y_clean.iloc[split_idx:]
        df_test = df_clean.iloc[split_idx:]

        print(f"  - Train: {len(X_train)}ê°œ ({X_train.index[0].date()} ~ {X_train.index[-1].date()})")
        print(f"  - Test:  {len(X_test)}ê°œ ({X_test.index[0].date()} ~ {X_test.index[-1].date()})")

        # 4. ì •ê·œí™”
        print(f"\n4ï¸âƒ£ ì •ê·œí™” (StandardScaler)...")
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        print(f"  âœ… ì™„ë£Œ")

        # 5. ëª¨ë¸ í•™ìŠµ
        print(f"\n5ï¸âƒ£ Logistic Regression í•™ìŠµ...")
        model = LogisticRegression(random_state=42, max_iter=1000)
        model.fit(X_train_scaled, y_train)
        print(f"  âœ… í•™ìŠµ ì™„ë£Œ")

        # 6. ì˜ˆì¸¡
        print(f"\n6ï¸âƒ£ ì˜ˆì¸¡ ë° í‰ê°€...")
        y_train_pred = model.predict(X_train_scaled)
        y_test_pred = model.predict(X_test_scaled)

        train_accuracy = accuracy_score(y_train, y_train_pred)
        test_accuracy = accuracy_score(y_test, y_test_pred)
        test_f1 = f1_score(y_test, y_test_pred, zero_division=0)

        print(f"  - Train ì •í™•ë„: {train_accuracy*100:.2f}%")
        print(f"  - Test ì •í™•ë„:  {test_accuracy*100:.2f}%")
        print(f"  - Test F1-Score: {test_f1:.3f}")

        # 7. ë°±í…ŒìŠ¤íŒ…
        print(f"\n7ï¸âƒ£ ë°±í…ŒìŠ¤íŒ…...")

        # ML ì „ëµ ìˆ˜ìµë¥ 
        df_test_copy = df_test.copy()
        df_test_copy['prediction'] = y_test_pred
        df_test_copy['actual_return'] = df_test_copy['Close'].pct_change().shift(-1) * 100

        # ë§¤ìˆ˜ ì‹ í˜¸ì¼ ë•Œë§Œ ìˆ˜ìµ ê³„ì‚°
        df_test_copy['strategy_return'] = 0.0
        df_test_copy.loc[df_test_copy['prediction'] == 1, 'strategy_return'] = df_test_copy['actual_return']

        # ëˆ„ì  ìˆ˜ìµë¥ 
        ml_cumulative_return = (1 + df_test_copy['strategy_return'] / 100).prod() - 1
        ml_return_pct = ml_cumulative_return * 100

        # Buy & Hold ìˆ˜ìµë¥ 
        bh_return_pct = (df_test['Close'].iloc[-1] / df_test['Close'].iloc[0] - 1) * 100

        # ì´ˆê³¼ ìˆ˜ìµ
        excess_return = ml_return_pct - bh_return_pct

        # ìŠ¹ë¥ 
        winning_trades = df_test_copy[
            (df_test_copy['prediction'] == 1) &
            (df_test_copy['actual_return'] > 0)
        ]
        total_trades = (df_test_copy['prediction'] == 1).sum()
        win_rate = len(winning_trades) / total_trades * 100 if total_trades > 0 else 0

        print(f"  - ML Strategy:  {ml_return_pct:+.2f}%")
        print(f"  - Buy & Hold:   {bh_return_pct:+.2f}%")
        print(f"  - ì´ˆê³¼ ìˆ˜ìµ:    {excess_return:+.2f}%p")
        print(f"  - ìŠ¹ë¥ :         {win_rate:.1f}% ({len(winning_trades)}/{total_trades})")

        # 8. ëª¨ë¸ ì €ì¥
        if save_model:
            print(f"\n8ï¸âƒ£ ëª¨ë¸ ì €ì¥...")
            models_dir = os.path.join(os.path.dirname(__file__), '..', 'models')
            os.makedirs(models_dir, exist_ok=True)

            model_data = {
                'model': model,
                'scaler': scaler,
                'feature_names': feature_cols,
                'train_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'performance': {
                    'train_accuracy': train_accuracy,
                    'test_accuracy': test_accuracy,
                    'test_f1': test_f1,
                    'ml_return': ml_return_pct,
                    'bh_return': bh_return_pct,
                    'excess_return': excess_return,
                    'win_rate': win_rate,
                    'num_trades': total_trades
                }
            }

            model_path = os.path.join(models_dir, f'{ticker.lower()}_top10_logistic.pkl')
            with open(model_path, 'wb') as f:
                pickle.dump(model_data, f)

            print(f"  âœ… ì €ì¥: {model_path}")

        print(f"\nâœ… {ticker} ì™„ë£Œ!")

        return {
            'ticker': ticker,
            'success': True,
            'train_accuracy': train_accuracy,
            'test_accuracy': test_accuracy,
            'test_f1': test_f1,
            'ml_return': ml_return_pct,
            'bh_return': bh_return_pct,
            'excess_return': excess_return,
            'win_rate': win_rate,
            'num_trades': total_trades,
            'train_samples': len(X_train),
            'test_samples': len(X_test)
        }

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

        return {
            'ticker': ticker,
            'success': False,
            'error': str(e)
        }


def main():
    print("=" * 70)
    print("ğŸš€ TOP 10 ì¢…ëª© ëª¨ë¸ í•™ìŠµ ë° ë°±í…ŒìŠ¤íŒ…")
    print("=" * 70)

    print(f"\nğŸ“‹ ëŒ€ìƒ ì¢…ëª© ({len(TOP10_TICKERS)}ê°œ):")
    for i, ticker in enumerate(TOP10_TICKERS, 1):
        print(f"  {i:2d}. {ticker}")

    results = []

    for ticker in TOP10_TICKERS:
        result = train_and_backtest(ticker, save_model=True)
        if result:
            results.append(result)

    # ìµœì¢… ìš”ì•½
    print("\n\n" + "=" * 70)
    print("ğŸ“Š ìµœì¢… ìš”ì•½")
    print("=" * 70)

    success_results = [r for r in results if r['success']]
    failed_results = [r for r in results if not r['success']]

    if success_results:
        print(f"\nâœ… ì„±ê³µ ({len(success_results)}ê°œ):")
        print(f"\n{'Ticker':<8} {'Test Acc':>10} {'F1':>8} {'ML Ret':>10} {'B&H':>10} {'Excess':>10} {'Win%':>8} {'Trades':>8}")
        print("-" * 70)

        for r in success_results:
            print(f"{r['ticker']:<8} {r['test_accuracy']*100:>9.2f}% "
                  f"{r['test_f1']:>8.3f} {r['ml_return']:>9.2f}% "
                  f"{r['bh_return']:>9.2f}% {r['excess_return']:>9.2f}%p "
                  f"{r['win_rate']:>7.1f}% {r['num_trades']:>8d}")

    if failed_results:
        print(f"\nâŒ ì‹¤íŒ¨ ({len(failed_results)}ê°œ):")
        for r in failed_results:
            print(f"  - {r['ticker']}: {r.get('error', 'Unknown')}")

    # í†µê³„
    if success_results:
        print(f"\nğŸ“ˆ í†µê³„:")
        print(f"  - ì´ ì¢…ëª©: {len(TOP10_TICKERS)}ê°œ")
        print(f"  - ì„±ê³µ: {len(success_results)}ê°œ")
        print(f"  - ì‹¤íŒ¨: {len(failed_results)}ê°œ")
        print(f"  - ì„±ê³µë¥ : {len(success_results)/len(TOP10_TICKERS)*100:.1f}%")

        avg_test_acc = np.mean([r['test_accuracy'] for r in success_results])
        avg_f1 = np.mean([r['test_f1'] for r in success_results])
        avg_ml_return = np.mean([r['ml_return'] for r in success_results])
        avg_bh_return = np.mean([r['bh_return'] for r in success_results])
        avg_excess = np.mean([r['excess_return'] for r in success_results])
        avg_win_rate = np.mean([r['win_rate'] for r in success_results])

        print(f"\nğŸ“Š í‰ê· :")
        print(f"  - Test ì •í™•ë„: {avg_test_acc*100:.2f}%")
        print(f"  - F1-Score: {avg_f1:.3f}")
        print(f"  - ML ìˆ˜ìµë¥ : {avg_ml_return:+.2f}%")
        print(f"  - B&H ìˆ˜ìµë¥ : {avg_bh_return:+.2f}%")
        print(f"  - ì´ˆê³¼ ìˆ˜ìµ: {avg_excess:+.2f}%p")
        print(f"  - ìŠ¹ë¥ : {avg_win_rate:.1f}%")

        # ìµœê³  ì„±ëŠ¥
        best_ml = max(success_results, key=lambda x: x['ml_return'])
        best_excess = max(success_results, key=lambda x: x['excess_return'])
        best_f1 = max(success_results, key=lambda x: x['test_f1'])

        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥:")
        print(f"  - ìµœê³  ML ìˆ˜ìµë¥ : {best_ml['ticker']} ({best_ml['ml_return']:+.2f}%)")
        print(f"  - ìµœê³  ì´ˆê³¼ ìˆ˜ìµ: {best_excess['ticker']} ({best_excess['excess_return']:+.2f}%p)")
        print(f"  - ìµœê³  F1-Score: {best_f1['ticker']} ({best_f1['test_f1']:.3f})")

        # ê²°ê³¼ ì €ì¥
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥...")
        results_dir = os.path.join(os.path.dirname(__file__), '..', 'results')
        os.makedirs(results_dir, exist_ok=True)

        comparison_df = pd.DataFrame(success_results)
        comparison_file = os.path.join(results_dir, 'top10_model_comparison.csv')
        comparison_df.to_csv(comparison_file, index=False)

        print(f"  âœ… {comparison_file}")

    print("\n" + "=" * 70)
    print("âœ¨ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    print("=" * 70)


if __name__ == "__main__":
    main()
