"""
Step 3: ë¡œì§€ìŠ¤í‹± íšŒê·€ í•™ìŠµ

ğŸ¯ ëª©ì :
ê°€ì¥ ë‹¨ìˆœí•œ ëª¨ë¸ë¡œ ê³¼ì í•© ê·¼ë³¸ í•´ê²°

ğŸ“š ë¡œì§€ìŠ¤í‹± íšŒê·€ë€?
- ê°€ì¥ ê¸°ë³¸ì ì¸ ë¶„ë¥˜ ëª¨ë¸
- ì„ í˜• ê²°í•© â†’ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ â†’ 0 or 1
- ê³¼ì í•© ìœ„í—˜ ë‚®ìŒ (íŒŒë¼ë¯¸í„° ì ìŒ)
- ë°ì´í„° ì ì„ ë•Œ íš¨ê³¼ì 

ğŸ’¡ ì™œ ì‹œë„í•˜ë‚˜?
- Random Forest: ë³µì¡í•¨ (íŠ¸ë¦¬ 100ê°œ)
- ë¡œì§€ìŠ¤í‹± íšŒê·€: ë‹¨ìˆœí•¨ (ì„ í˜•)
- ë°ì´í„° 77ê°œ â†’ ë‹¨ìˆœí•œ ëª¨ë¸ì´ ë‚˜ì„ ìˆ˜ë„
"""

import sys
import os
import io
import platform

# Windows í•œê¸€/ì´ëª¨ì§€ ì¶œë ¥ ì„¤ì •
if platform.system() == 'Windows':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

from core.feature_engineer import FeatureEngineer
from core.ml_trainer import MLTrainer


def main():
    print("=" * 70)
    print("ğŸ¤– Step 3: ë¡œì§€ìŠ¤í‹± íšŒê·€ í•™ìŠµ")
    print("=" * 70)

    # ========================================
    # 1. ë°ì´í„° ì¤€ë¹„
    # ========================================
    print("\nğŸ“ ë°ì´í„° ë¡œë”©...")

    data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'tsla_optimized_90days.csv')
    df = pd.read_csv(data_path, index_col=0)

    engineer = FeatureEngineer(label_threshold=1.0)
    X, y = engineer.prepare_ml_data(df)

    print(f"âœ… íŠ¹ì§•: {X.shape[1]}ê°œ, ë°ì´í„°: {len(X)}ê°œ")

    # ========================================
    # 2. Train/Test ë¶„í•  ë° ì •ê·œí™”
    # ========================================
    trainer = MLTrainer(test_size=0.2, random_state=42)

    X_train, X_test, y_train, y_test = trainer.split_data(X, y)
    X_train_scaled, X_test_scaled = trainer.normalize_data(X_train, X_test)

    # ========================================
    # 3. ë¡œì§€ìŠ¤í‹± íšŒê·€ í•™ìŠµ
    # ========================================
    print("\nğŸ“Š [ëª¨ë¸ A] ë¡œì§€ìŠ¤í‹± íšŒê·€...")

    # ğŸ’¡ C: ì •ê·œí™” ê°•ë„ (ì‘ì„ìˆ˜ë¡ ê°•í•¨)
    # ğŸ’¡ class_weight='balanced': í´ë˜ìŠ¤ ë¶ˆê· í˜• ìë™ ì¡°ì •
    lr_model = LogisticRegression(
        C=1.0,                    # ê¸°ë³¸ê°’
        max_iter=1000,            # ì¶©ë¶„í•œ ë°˜ë³µ
        random_state=42,
        class_weight='balanced'   # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡°ì •
    )

    print(f"  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
    print(f"    - C (ì •ê·œí™”): 1.0")
    print(f"    - Class Weight: balanced")
    print(f"\n  í•™ìŠµ ì¤‘...")

    lr_model.fit(X_train_scaled, y_train)
    print(f"âœ… í•™ìŠµ ì™„ë£Œ")

    # ì˜ˆì¸¡
    y_pred_train = lr_model.predict(X_train_scaled)
    y_pred_test = lr_model.predict(X_test_scaled)

    # í‰ê°€
    lr_results = {
        'train_accuracy': accuracy_score(y_train, y_pred_train),
        'test_accuracy': accuracy_score(y_test, y_pred_test),
        'test_precision': precision_score(y_test, y_pred_test, zero_division=0),
        'test_recall': recall_score(y_test, y_pred_test, zero_division=0),
        'test_f1': f1_score(y_test, y_pred_test, zero_division=0),
        'confusion_matrix': confusion_matrix(y_test, y_pred_test)
    }

    print(f"\nğŸ“ˆ ì„±ëŠ¥:")
    print(f"  - Train Accuracy: {lr_results['train_accuracy']*100:.2f}%")
    print(f"  - Test Accuracy: {lr_results['test_accuracy']*100:.2f}%")
    print(f"  - Test Precision: {lr_results['test_precision']*100:.2f}%")
    print(f"  - Test Recall: {lr_results['test_recall']*100:.2f}%")
    print(f"  - Test F1-Score: {lr_results['test_f1']:.3f}")
    print(f"  - Overfit Gap: {(lr_results['train_accuracy'] - lr_results['test_accuracy'])*100:.1f}%p")

    cm = lr_results['confusion_matrix']
    print(f"\n  ğŸ“Š Confusion Matrix:")
    print(f"                ì˜ˆì¸¡ ë§¤ë„(0)  ì˜ˆì¸¡ ë§¤ìˆ˜(1)")
    print(f"  ì‹¤ì œ ë§¤ë„(0)      {cm[0,0]:3d}         {cm[0,1]:3d}")
    print(f"  ì‹¤ì œ ë§¤ìˆ˜(1)      {cm[1,0]:3d}         {cm[1,1]:3d}")

    # ========================================
    # 4. Random Forest (ìµœì ) ì¬í•™ìŠµ for ë¹„êµ
    # ========================================
    print("\n\nğŸ“Š [ëª¨ë¸ B] Random Forest (ìµœì  íŒŒë¼ë¯¸í„°)...")

    trainer_rf = MLTrainer(test_size=0.2, random_state=42)
    X_train, X_test, y_train, y_test = trainer_rf.split_data(X, y)
    X_train_scaled, X_test_scaled = trainer_rf.normalize_data(X_train, X_test)

    trainer_rf.train_random_forest(
        X_train_scaled,
        y_train,
        n_estimators=100,
        max_depth=5,
        min_samples_split=10,
        min_samples_leaf=10
    )

    rf_results = trainer_rf.evaluate_model(
        X_test_scaled,
        y_test,
        X_train_scaled,
        y_train
    )

    # ========================================
    # 5. ê²°ê³¼ ë¹„êµ
    # ========================================
    print("\n\n" + "="*70)
    print("ğŸ“Š ìµœì¢… ë¹„êµ: ë¡œì§€ìŠ¤í‹± íšŒê·€ vs Random Forest")
    print("="*70)

    comparison = pd.DataFrame({
        'ì§€í‘œ': ['Train Accuracy', 'Test Accuracy', 'Test Precision',
                'Test Recall', 'Test F1-Score', 'Overfit Gap'],
        'ë¡œì§€ìŠ¤í‹± íšŒê·€': [
            f"{lr_results['train_accuracy']*100:.2f}%",
            f"{lr_results['test_accuracy']*100:.2f}%",
            f"{lr_results['test_precision']*100:.2f}%",
            f"{lr_results['test_recall']*100:.2f}%",
            f"{lr_results['test_f1']:.3f}",
            f"{(lr_results['train_accuracy'] - lr_results['test_accuracy'])*100:.1f}%p"
        ],
        'Random Forest': [
            f"{rf_results['train_accuracy']*100:.2f}%",
            f"{rf_results['test_accuracy']*100:.2f}%",
            f"{rf_results['test_precision']*100:.2f}%",
            f"{rf_results['test_recall']*100:.2f}%",
            f"{rf_results['test_f1']:.3f}",
            f"{(rf_results['train_accuracy'] - rf_results['test_accuracy'])*100:.1f}%p"
        ]
    })

    print("\n")
    print(comparison.to_string(index=False))

    # ========================================
    # 6. ì¸ì‚¬ì´íŠ¸
    # ========================================
    print("\n\nğŸ’¡ ì¸ì‚¬ì´íŠ¸:")

    # Test Accuracy
    acc_diff = lr_results['test_accuracy'] - rf_results['test_accuracy']
    if acc_diff > 0.05:
        print(f"  âœ… ë¡œì§€ìŠ¤í‹± íšŒê·€ê°€ Test Accuracy {acc_diff*100:.1f}%p ìš°ìˆ˜!")
    elif acc_diff < -0.05:
        print(f"  âš ï¸  Random Forestê°€ Test Accuracy {abs(acc_diff)*100:.1f}%p ìš°ìˆ˜")
    else:
        print(f"  â– Test Accuracy ë¹„ìŠ· (ì°¨ì´ {abs(acc_diff)*100:.1f}%p)")

    # Overfit Gap
    gap_lr = lr_results['train_accuracy'] - lr_results['test_accuracy']
    gap_rf = rf_results['train_accuracy'] - rf_results['test_accuracy']
    gap_diff = gap_rf - gap_lr

    if gap_diff > 0.05:
        print(f"  âœ… ë¡œì§€ìŠ¤í‹± íšŒê·€ê°€ ê³¼ì í•© {gap_diff*100:.1f}%p ì ìŒ! (ë” ì•ˆì •ì )")
    elif gap_diff < -0.05:
        print(f"  âš ï¸  Random Forestê°€ ê³¼ì í•© {abs(gap_diff)*100:.1f}%p ì ìŒ")
    else:
        print(f"  â– ê³¼ì í•© ì •ë„ ë¹„ìŠ·")

    # F1-Score
    f1_diff = lr_results['test_f1'] - rf_results['test_f1']
    if f1_diff > 0:
        print(f"  âœ… ë¡œì§€ìŠ¤í‹± íšŒê·€ê°€ F1-Score {f1_diff:.3f} ìš°ìˆ˜!")
    else:
        print(f"  â– Random Forestê°€ F1-Score {abs(f1_diff):.3f} ìš°ìˆ˜")

    # ìµœì¢… ì¶”ì²œ
    print(f"\nğŸ† ìµœì¢… ì¶”ì²œ:")
    if lr_results['test_f1'] > rf_results['test_f1'] and gap_lr < gap_rf:
        print(f"  ë¡œì§€ìŠ¤í‹± íšŒê·€ ì‚¬ìš© ê¶Œì¥ (ì„±ëŠ¥ ìš°ìˆ˜ + ê³¼ì í•© ì ìŒ)")
        best_model = 'logistic_regression'
        best_results = lr_results
    elif rf_results['test_f1'] > lr_results['test_f1']:
        print(f"  Random Forest ì‚¬ìš© ê¶Œì¥ (F1-Score ìš°ìˆ˜)")
        best_model = 'random_forest'
        best_results = rf_results
    else:
        print(f"  ë‘ ëª¨ë¸ ì„±ëŠ¥ ë¹„ìŠ·, Random Forest ì„ íƒ (ë” ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ ê°€ëŠ¥)")
        best_model = 'random_forest'
        best_results = rf_results

    # ========================================
    # 7. ê²°ê³¼ ì €ì¥
    # ========================================
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥...")

    results_dir = os.path.join(os.path.dirname(__file__), '..', 'results')

    # ë¹„êµ ê²°ê³¼ ì €ì¥
    comparison_path = os.path.join(results_dir, 'lr_vs_rf_comparison.csv')
    comparison.to_csv(comparison_path, index=False)
    print(f"âœ… ë¹„êµ ê²°ê³¼ ì €ì¥: {comparison_path}")

    # ì„±ëŠ¥ ìš”ì•½
    summary = pd.DataFrame({
        'model': ['Logistic Regression', 'Random Forest', 'Best'],
        'test_accuracy': [
            lr_results['test_accuracy'],
            rf_results['test_accuracy'],
            best_results['test_accuracy']
        ],
        'test_f1': [
            lr_results['test_f1'],
            rf_results['test_f1'],
            best_results['test_f1']
        ],
        'overfit_gap': [
            gap_lr,
            gap_rf,
            gap_lr if best_model == 'logistic_regression' else gap_rf
        ],
        'recommended': [
            'Yes' if best_model == 'logistic_regression' else 'No',
            'Yes' if best_model == 'random_forest' else 'No',
            'Yes'
        ]
    })

    summary_path = os.path.join(results_dir, 'model_comparison_summary.csv')
    summary.to_csv(summary_path, index=False)
    print(f"âœ… ëª¨ë¸ ë¹„êµ ìš”ì•½ ì €ì¥: {summary_path}")

    print("\n" + "="*70)
    print("âœ¨ Step 3 ì™„ë£Œ!")
    print("="*70)


if __name__ == "__main__":
    main()
