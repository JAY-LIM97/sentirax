"""
Step 2: íŠ¹ì§• ì„ íƒ í›„ ì¬í•™ìŠµ

ğŸ¯ ëª©ì :
ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì§•ë§Œ ì‚¬ìš©í•˜ì—¬ ê³¼ì í•© ë°©ì§€

ğŸ“Š ì´ì „ Feature Importance ìƒìœ„ 10ê°œ:
1. oil (11.55%)
2. volatility_5d (10.21%)
3. vix_lag1 (10.02%)
4. volume_ratio (8.41%)
5. ma_5 (8.24%)
6. treasury_10y (5.38%)
7. vix (5.33%)
8. ma_20 (4.78%)
9. return_20d (4.66%)
10. volume_ma_20 (4.58%)
"""

import sys
import os
import io
import platform

# Windows í•œê¸€/ì´ëª¨ì§€ ì¶œë ¥ ì„¤ì •
if platform.system() == 'Windows':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from core.feature_engineer import FeatureEngineer
from core.ml_trainer import MLTrainer


def main():
    print("=" * 70)
    print("ğŸ“Š Step 2: íŠ¹ì§• ì„ íƒ í›„ ì¬í•™ìŠµ")
    print("=" * 70)

    # ========================================
    # 1. ë°ì´í„° ì¤€ë¹„
    # ========================================
    print("\nğŸ“ ë°ì´í„° ë¡œë”©...")

    data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'tsla_optimized_90days.csv')
    df = pd.read_csv(data_path, index_col=0)

    engineer = FeatureEngineer(label_threshold=1.0)
    X_full, y = engineer.prepare_ml_data(df)

    print(f"âœ… ì „ì²´ íŠ¹ì§•: {X_full.shape[1]}ê°œ")

    # ========================================
    # 2. ìƒìœ„ 10ê°œ íŠ¹ì§• ì„ íƒ
    # ========================================
    print("\nğŸ” ìƒìœ„ 10ê°œ íŠ¹ì§• ì„ íƒ...")

    # ì´ì „ ê²°ê³¼ì—ì„œ í™•ì¸ëœ ìƒìœ„ 10ê°œ
    top_features = [
        'oil',
        'volatility_5d',
        'vix_lag1',
        'volume_ratio',
        'ma_5',
        'treasury_10y',
        'vix',
        'ma_20',
        'return_20d',
        'volume_ma_20'
    ]

    # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” íŠ¹ì§•ë§Œ ì„ íƒ
    selected_features = [f for f in top_features if f in X_full.columns]
    X_selected = X_full[selected_features]

    print(f"âœ… ì„ íƒëœ íŠ¹ì§• ({len(selected_features)}ê°œ):")
    for i, feat in enumerate(selected_features, 1):
        print(f"  {i:2d}. {feat}")

    # ========================================
    # 3. ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµ (ì „ì²´ íŠ¹ì§•)
    # ========================================
    print("\n\n" + "="*70)
    print("ğŸŒ² [ë¹„êµ A] ì „ì²´ íŠ¹ì§• (26ê°œ) + ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°")
    print("="*70)

    trainer_full = MLTrainer(test_size=0.2, random_state=42)
    trainer_full.feature_names = X_full.columns.tolist()

    X_train_full, X_test_full, y_train, y_test = trainer_full.split_data(X_full, y)
    X_train_full_scaled, X_test_full_scaled = trainer_full.normalize_data(X_train_full, X_test_full)

    # Step 1ì—ì„œ ì°¾ì€ ìµœì  íŒŒë¼ë¯¸í„°
    trainer_full.train_random_forest(
        X_train_full_scaled,
        y_train,
        n_estimators=100,
        max_depth=5,
        min_samples_split=10,
        min_samples_leaf=10
    )

    results_full = trainer_full.evaluate_model(
        X_test_full_scaled,
        y_test,
        X_train_full_scaled,
        y_train
    )

    # ========================================
    # 4. ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµ (ì„ íƒëœ íŠ¹ì§•)
    # ========================================
    print("\n\n" + "="*70)
    print(f"ğŸ¯ [ë¹„êµ B] ì„ íƒëœ íŠ¹ì§• ({len(selected_features)}ê°œ) + ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°")
    print("="*70)

    trainer_selected = MLTrainer(test_size=0.2, random_state=42)
    trainer_selected.feature_names = X_selected.columns.tolist()

    X_train_sel, X_test_sel, y_train, y_test = trainer_selected.split_data(X_selected, y)
    X_train_sel_scaled, X_test_sel_scaled = trainer_selected.normalize_data(X_train_sel, X_test_sel)

    trainer_selected.train_random_forest(
        X_train_sel_scaled,
        y_train,
        n_estimators=100,
        max_depth=5,
        min_samples_split=10,
        min_samples_leaf=10
    )

    results_selected = trainer_selected.evaluate_model(
        X_test_sel_scaled,
        y_test,
        X_train_sel_scaled,
        y_train
    )

    # ========================================
    # 5. ê²°ê³¼ ë¹„êµ
    # ========================================
    print("\n\n" + "="*70)
    print("ğŸ“Š ìµœì¢… ë¹„êµ")
    print("="*70)

    comparison = pd.DataFrame({
        'ì§€í‘œ': ['íŠ¹ì§• ìˆ˜', 'Train Accuracy', 'Test Accuracy', 'Test Precision',
                'Test Recall', 'Test F1-Score', 'Overfit Gap'],
        'ì „ì²´ íŠ¹ì§• (26ê°œ)': [
            26,
            f"{results_full['train_accuracy']*100:.2f}%",
            f"{results_full['test_accuracy']*100:.2f}%",
            f"{results_full['test_precision']*100:.2f}%",
            f"{results_full['test_recall']*100:.2f}%",
            f"{results_full['test_f1']:.3f}",
            f"{(results_full['train_accuracy'] - results_full['test_accuracy'])*100:.1f}%p"
        ],
        f'ì„ íƒëœ íŠ¹ì§• ({len(selected_features)}ê°œ)': [
            len(selected_features),
            f"{results_selected['train_accuracy']*100:.2f}%",
            f"{results_selected['test_accuracy']*100:.2f}%",
            f"{results_selected['test_precision']*100:.2f}%",
            f"{results_selected['test_recall']*100:.2f}%",
            f"{results_selected['test_f1']:.3f}",
            f"{(results_selected['train_accuracy'] - results_selected['test_accuracy'])*100:.1f}%p"
        ]
    })

    print("\n")
    print(comparison.to_string(index=False))

    # ========================================
    # 6. ì¸ì‚¬ì´íŠ¸
    # ========================================
    print("\n\nğŸ’¡ ì¸ì‚¬ì´íŠ¸:")

    # Test Accuracy ë¹„êµ
    acc_diff = results_selected['test_accuracy'] - results_full['test_accuracy']
    if acc_diff > 0:
        print(f"  âœ… íŠ¹ì§• ì„ íƒìœ¼ë¡œ Test Accuracy {acc_diff*100:.1f}%p í–¥ìƒ!")
    elif acc_diff < -0.05:
        print(f"  âš ï¸  íŠ¹ì§• ì„ íƒìœ¼ë¡œ Test Accuracy {abs(acc_diff)*100:.1f}%p í•˜ë½")
    else:
        print(f"  â– Test Accuracy ë¹„ìŠ· (ì°¨ì´ {abs(acc_diff)*100:.1f}%p)")

    # Overfit Gap ë¹„êµ
    gap_full = results_full['train_accuracy'] - results_full['test_accuracy']
    gap_selected = results_selected['train_accuracy'] - results_selected['test_accuracy']
    gap_diff = gap_full - gap_selected

    if gap_diff > 0.05:
        print(f"  âœ… ê³¼ì í•© {gap_diff*100:.1f}%p ê°ì†Œ! (ë” ì•ˆì •ì )")
    elif gap_diff < -0.05:
        print(f"  âš ï¸  ê³¼ì í•© {abs(gap_diff)*100:.1f}%p ì¦ê°€")
    else:
        print(f"  â– ê³¼ì í•© ì •ë„ ë¹„ìŠ·")

    # F1-Score ë¹„êµ
    f1_diff = results_selected['test_f1'] - results_full['test_f1']
    if f1_diff > 0:
        print(f"  âœ… F1-Score {f1_diff:.3f} í–¥ìƒ!")
    else:
        print(f"  â– F1-Score {abs(f1_diff):.3f} í•˜ë½")

    # ========================================
    # 7. ê²°ê³¼ ì €ì¥
    # ========================================
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥...")

    results_dir = os.path.join(os.path.dirname(__file__), '..', 'results')

    # ë¹„êµ ê²°ê³¼ ì €ì¥
    comparison_path = os.path.join(results_dir, 'feature_selection_comparison.csv')
    comparison.to_csv(comparison_path, index=False)
    print(f"âœ… ë¹„êµ ê²°ê³¼ ì €ì¥: {comparison_path}")

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
    if results_selected['test_f1'] >= results_full['test_f1']:
        print(f"\nğŸ† ì„ íƒëœ íŠ¹ì§• ëª¨ë¸ì´ ë” ìš°ìˆ˜!")
        models_dir = os.path.join(os.path.dirname(__file__), '..', 'models')
        trainer_selected.save_model(save_dir=models_dir, model_name='rf_selected_features')
    else:
        print(f"\nğŸ† ì „ì²´ íŠ¹ì§• ëª¨ë¸ì´ ë” ìš°ìˆ˜")

    print("\n" + "="*70)
    print("âœ¨ Step 2 ì™„ë£Œ!")
    print("="*70)


if __name__ == "__main__":
    main()
